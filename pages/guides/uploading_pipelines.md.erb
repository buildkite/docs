# Uploading Build Pipelines

In addition to defining your build pipelines via the web you can use your Buildkite agent’s `pipeline upload` command to read them from your source code, or even dynamically generate them using a script. This allows you to version, audit and review your build pipelines alongside your source code.

<%= toc %>

## Getting started

To get started on a new project create a single step in your project’s build pipeline and have it run `buildkite-agent pipeline upload`:

<%= image("pipeline-upload-step.png", width: 1080/2, height: 532/2) %>

This command will expect a file located at `.buildkite/pipeline.yml` within your source code. For example, here's a pipeline that simply prints “Hello!”:

```yml
steps:
  - name: Example Test
    command: echo "Hello!"
```

To test your new `pipeline.yml` simply commit and push the file, and run a new build:

<%= image("show-example-test.png", width: 422/2, height: 270/2) %>

## Pipeline format

The pipeline can be uploaded as YML and JSON, and they both have the same structure. There are two top level properties:

* `env` - a hash of build-wide environment variables
* `steps` - an array of build steps to be run (a mix of script, waiter and blocker steps)

A *script* step runs a command on an agent. The following is the most simple script step:

```yml
steps:
  - command: command.sh
```

A more complicated example of a script step, showing all the possible configuration keys:

```yml
steps:
  - command: deploy.sh
    name: Deploy
    branches: master
    env:
      FOO: bar
    agents:
      npm: true
      queue: deploy
    artifact_paths: "logs/**/*;coverage/**/*"
    parallelism: 1
    concurrency: 1
    concurrency_group: deploy
    timeout_in_minutes: 60
```

A *waiter* step waits for all previous steps to complete before continuing, for example:

```yml
steps:
  - command: command.sh
  - wait
  - command: echo The command passed
```

A *blocker* step will pause the pipeline and wait for a team member to unblock it (via the web or the API).

```yml
steps:
  - command: command.sh
  - block
  - command: deploy.sh
    name: ":rocket: Deploy"
```

## Dynamic pipelines

You can generate pipelines dynamically from your source code thanks to the fact that pipelines are uploaded by running a command on one of your Buildkite agents. This provides you with a large amount of flexiblity to structure your projects as you wish.

For example you could generate a list of parallel test steps based upon the `test/*` directories within your repository. To do this you'd have a single step in your project settings:

```
./scripts/buildkite_test_pipeline | buildkite-agent pipeline upload
```

The `scripts/buildkite_test_pipeline` would be an executable file checked into your source repository, and could look something like the following:

```
#!/bin/bash

# Generates a pipeline step for each test directory, allowing the tests to be
# split up and run across distributed build agents

set -eu

echo "steps:"

for test_dir in test/*/; do
  echo "  - command: \"run_tests "${test_dir}"\"
done
```

When this is run on an agent it will output the pipeline, which is then piped to the `buildkite-agent pipeline upload` command.

## Pipeline command

Use this command in your build scripts to upload pipelines to Buildkite.

```
Usage:

   buildkite-agent pipeline upload <file> [arguments...]

Description:

   Allows you to change the pipeline of a running build by uploading either a
   JSON or YAML configuration file. If no configuration file is provided,
   we look for the file in the following locations:

   - .buildkite/pipeline.yml
   - .buildkite/pipeline.json

   You can also pipe build pipelines to the command, allowing you to create scripts
   that generate dynamic pipelines.

Example:

   $ buildkite-agent pipeline upload
   $ buildkite-agent pipeline upload my-custom-steps.json
   $ ./script/dynamic_step_generator | buildkite-agent pipeline upload

Options:

   --replace                                    Replace the rest of the existing pipeline with the steps uploaded. Jobs that are already running are not removed. [$BUILDKITE_PIPELINE_REPLACE]
   --job                                        The job that is making the changes to it's build [$BUILDKITE_JOB_ID]
   --agent-access-token                         The access token used to identify the agent [$BUILDKITE_AGENT_ACCESS_TOKEN]
   --endpoint 'https://agent.buildkite.com/v3'  The Agent API endpoint [$BUILDKITE_AGENT_ENDPOINT]
   --no-color                                   Don't show colors in logging [$BUILDKITE_AGENT_NO_COLOR]
   --debug                                      Enable debug mode [$BUILDKITE_AGENT_DEBUG]
   --debug-http                                 Enable HTTP debug mode, which dumps all request and response bodies to the log [$BUILDKITE_AGENT_DEBUG_HTTP]
```

## Migrating existing projects

To migrate to checked in pipelines without interrupting existing branches you can add a new step at the start of the pipeline. This new step is reponsible for checking if a pipeline file exists and replacing the currently running pipeline (the old configuration, defined via the web) with the new configuration read from the file.

To do this, create a step with the following command:

```bash
[[ -f ".buildkite/pipeline.yml" ]] && buildkite-agent pipeline upload --replace || true
```

If the pipeline file exists then we execute the `pipeline upload --replace` command which will replace any steps that were defined via the web UI after this step.

## Controlling Concurrency

To control concurrency for a particular type of job specify a `concurrency_group` identifier (e.g. `"deploy"`) and a `concurrency` value (e.g. as `1`). The identifier is used across all of the project’s builds to identify and throttle the number of jobs running simulatenously.
