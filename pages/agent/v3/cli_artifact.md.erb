# buildkite-agent artifact

The Buildkite Agent’s `artifact` command provides support for uploading and downloading of build artifacts, allowing you to share binary data between build steps no matter the machine or network.

See the [Using Build Artifacts](/docs/builds/artifacts) guide for a step-by-step example.

{:toc}

## Uploading artifacts

You can use this command in your build scripts to store artifacts in the Buildkite artifact store. The stored artifacts will then be accessible via the web interface and can be downloaded by future build steps.

You can also configure the agent to automatically upload artifacts based on a file pattern (see the [Using Build Artifacts guide](/docs/builds/artifacts) for details).


<%= render 'agent/v3/help/artifact_upload' %>


### Artifact upload examples

Uploading a specific file:

```bash
buildkite-agent artifact upload log/test.log
```

Uploading all the jpegs and pngs, in all folders and subfolders:

```bash
buildkite-agent artifact upload "*/**/*.jpg;*/**/*.jpeg;*/**/*.png"
```

Uploading all the log files in the log folder:

```bash
buildkite-agent artifact upload "log/*.log"
```

Uploading all the files and folders inside the `coverage` directory:

```bash
buildkite-agent artifact upload "coverage/**/*"
```

Uploading a file name with special characters e.g. `hello??.html`:

```bash
buildkite-agent artifact upload "hello\?\?.html"
```

### Artifact upload glob syntax

Glob path patterns are used throughout Buildkite for specifying artifact uploads.

The source path you supply to the upload command will be replicated exactly at the destination. If you run:

```bash
buildkite-agent artifact upload log/test.log
```

Buildkite will store the file at `log/test.log`. If you want it to be stored as `test.log` without the full path, then you'll need to change into the file's directory before running your upload command:

```bash
cd log
buildkite-agent artifact upload test.log
```

Keep in mind while you’re writing your path pattern:

<!--alex ignore just-->

- patterns must match whole path strings, not just substrings
- there are two wildcards available that match non-separator characters (on Linux `/` is a separator character, and on Windows `\` is a separator character):
  + `*` to match a sequence of characters
  + `?` to match a single character
- character ranges surrounded by `[]` support the `^` as a negator
- special characters can be escaped with `\\`
- multiple paths are separated with `;`
- surround the pattern with quotes


## Downloading artifacts

Use this command in your build scripts to download artifacts.

<%= render 'agent/v3/help/artifact_download' %>

### Artifact download examples

Downloading a specific file into the current directory:

```bash
buildkite-agent artifact download build.zip .
```

Downloading a specific file into a specific directory (note the trailing slash):

```bash
buildkite-agent artifact download build.zip tmp/
```

Downloading all the files uploaded to `log` (including all subdirectories) into a local `log` directory (note that local directories will be created to match the uploaded file paths):

```bash
buildkite-agent artifact download "log/*" .
```

Downloading all the files uploaded to `coverage` (including all subdirectories) into a local `tmp/coverage` directory (note that local directories are created to match the uploaded file path):

```bash
buildkite-agent artifact download "coverage/*" tmp/
```

Downloading all images (from any directory) into a local `images/` directory (note that local directories are created to match the uploaded file path, and that you can run multiple download commands into the same directory):

```bash
buildkite-agent artifact download "*.jpg" images/
buildkite-agent artifact download "*.jpeg" images/
buildkite-agent artifact download "*.png" images/
```

### Artifact download pattern syntax

Artifact downloads support pattern-matching using the `*` character.

<!--alex ignore just-->

Unlike artifact upload glob patterns, these operate over the entire path and not just between separator characters. For example, a download path pattern of `log/*` matches all files under the log directory and all subdirectories.

There is no need to escape characters such as `?`, `[` and `]`.

## Downloading artifacts outside a running build

The `buildkite-agent artifact download` command relies on environment variables that are set by the agent while a build is running.

For example, executing the `buildkite-agent artifact download` command on your local machine would return an error about missing environment variables. However, when this command is executed as part of a build, the agent has set the required variables, and the command will be able to run.

If you want to download an artifact from outside a build use our [Artifact Download API](/docs/api/artifacts#download-an-artifact).

## Fetching the SHA of an artifact

Use this command in your build scripts to verify downloaded artifacts against the original SHA-1 of the file.


<%= render 'agent/v3/help/artifact_shasum' %>


## Using your private AWS S3 bucket

You can use the `buildkite-agent artifact` command to store artifacts in your private Amazon S3 bucket. To do so, you’ll need to export some artifact environment variables.

You can set these environment variables from a variety of places. Exporting them
from an [environment hook](/docs/agent/v3/hooks#job-lifecycle-hooks) defined in
your [agent `hooks-path` directory](/docs/agent/v3/hooks#hook-locations-agent-hooks)
ensures they are applied to all jobs:

```bash
export BUILDKITE_ARTIFACT_UPLOAD_DESTINATION="s3://name-of-your-s3-bucket/$BUILDKITE_JOB_ID"
export BUILDKITE_S3_DEFAULT_REGION="eu-central-1" # default: us-east-1
```

You will also need to make sure your agent instances have the following IAM policy to read and write objects in the bucket, for example:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:GetObjectAcl",
                "s3:GetObjectVersion",
                "s3:GetObjectVersionAcl",
                "s3:ListBucket",
                "s3:PutObject",
                "s3:PutObjectAcl",
                "s3:PutObjectVersionAcl"
            ],
            "Resource": [
               "arn\:aws\:s3:::my-s3-bucket",
               "arn\:aws\:s3:::my-s3-bucket/*"
            ]
        }
    ]
}
```

If you’re running your agents on an AWS EC2 Instance we suggest adding the above policy to [an IAM Role](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html). If you're running outside of AWS, or you’re unable to use an instance role, you can use export `BUILDKITE_S3_ACCESS_KEY_ID` and `BUILDKITE_S3_SECRET_ACCESS_KEY` containing the [Access Key credentials](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html) for an IAM user. See the [Managing Pipeline Secrets](/docs/pipelines/secrets) documentation for how to securely set up these environment variables.

By default the agent will create objects with `public-read` permissions, so that clicking on an artifact link in the Buildkite web interface can go directly to the S3 object to be viewed in the browser. You can set this to private by exporting the following environment variable:

```bash
export BUILDKITE_S3_ACL="private"
```

If you set your S3 ACL to `private` you won't be able to click through to the artifacts in the Buildkite web interface. You can use an authenticating S3 proxy such as [aws-s3-proxy](https://github.com/pottava/aws-s3-proxy) to provide web access protected by HTTP Basic authentication, which will allow you to view embedded assets such as HTML pages with images. To set the access URL for your proxy, export the following environment variable:

```bash
export BUILDKITE_S3_ACCESS_URL="https://buildkite-artifacts.example.com/"
```

See the BUILDKITE&#95;S3&#95;ACL variable in the [environment variables list](/docs/pipelines/environment-variables#bk-env-vars) for a full list of access control options.

## Using your private Google Cloud bucket

You can use the `buildkite-agent artifact` command to store artifacts in your private Google Cloud storage bucket. For instructions for how to set this up, see our [Google Cloud Installation Guide](/docs/agent/v3/gcloud#uploading-artifacts-to-google-cloud-storage).

## Using your Artifactory instance

You can use the `buildkite-agent artifact` command to store artifacts in Artifactory. For instructions for how to set this up, see our [Artifactory Guide](/docs/integrations/artifactory).
